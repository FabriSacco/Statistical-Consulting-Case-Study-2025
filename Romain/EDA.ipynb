{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Romain\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import startup_credit_2 as src_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_CSV      = r\"C:\\Users\\Romain\\OneDrive - KU Leuven\\Masters\\MBIS\\Year 2\\Semester 2\\Statistical Consulting\\ExternalData\\startup_failures.csv\"         # your Crunchbase-style file\n",
    "MACRO_FOLDER = \"ExternalData/\"             # contains inflation.csv, gdp_growth.csv, unemployment_rate.csv\n",
    "OUTPUT_PARQUET = \"scored.parquet\"\n",
    "cfg = src_2.DEFAULT_CFG.copy()\n",
    "cfg[\"momentum_variant\"] = \"auto\"           # or \"span\" / \"freq\" / \"recency\"\n",
    "cfg[\"stress_scenarios\"][\"mild\"] = {\"country_score_add\": 0.5}\n",
    "\n",
    "pl_df=src_2.load_and_clean(RAW_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "momentum-scores: 100%|██████████| 66368/66368 [00:26<00:00, 2478.47it/s]\n"
     ]
    }
   ],
   "source": [
    "df_comp = src_2.enrich_and_score(pl_df, learn_w=True, stress=\"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permalink</th>\n",
       "      <th>name</th>\n",
       "      <th>homepage_url</th>\n",
       "      <th>category_list</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>country_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>funding_rounds</th>\n",
       "      <th>...</th>\n",
       "      <th>score_momentum_avg_round</th>\n",
       "      <th>score_momentum_per_year</th>\n",
       "      <th>score_age</th>\n",
       "      <th>score_diversification</th>\n",
       "      <th>score_inflation</th>\n",
       "      <th>score_gdp_growth</th>\n",
       "      <th>score_unemployment_rate</th>\n",
       "      <th>score_total</th>\n",
       "      <th>rating</th>\n",
       "      <th>pd_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/organization/-fame</td>\n",
       "      <td>#fame</td>\n",
       "      <td>http://livfame.com</td>\n",
       "      <td>[Media]</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>16</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.587360</td>\n",
       "      <td>R5</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/organization/-qounter</td>\n",
       "      <td>:Qounter</td>\n",
       "      <td>http://www.qounter.com</td>\n",
       "      <td>[Application Platforms, Real Time, Social Netw...</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE - Other</td>\n",
       "      <td>Delaware City</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.614708</td>\n",
       "      <td>R4</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/organization/-the-one-of-them-inc-</td>\n",
       "      <td>(THE) ONE of THEM,Inc.</td>\n",
       "      <td>http://oneofthem.jp</td>\n",
       "      <td>[Apps, Games, Mobile]</td>\n",
       "      <td>3406878.0</td>\n",
       "      <td>JPN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6.732206</td>\n",
       "      <td>R5</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/organization/0-6-com</td>\n",
       "      <td>0-6.com</td>\n",
       "      <td>http://www.0-6.com</td>\n",
       "      <td>[Curated Web]</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>22</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.483330</td>\n",
       "      <td>R5</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/organization/004-technologies</td>\n",
       "      <td>004 Technologies</td>\n",
       "      <td>http://004gmbh.de/en/004-interact</td>\n",
       "      <td>[Software]</td>\n",
       "      <td>3200000.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>IL</td>\n",
       "      <td>Springfield, Illinois</td>\n",
       "      <td>Champaign</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.326976</td>\n",
       "      <td>R4</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             permalink                    name  \\\n",
       "0                  /organization/-fame                   #fame   \n",
       "1               /organization/-qounter                :Qounter   \n",
       "2  /organization/-the-one-of-them-inc-  (THE) ONE of THEM,Inc.   \n",
       "3                /organization/0-6-com                 0-6.com   \n",
       "4       /organization/004-technologies        004 Technologies   \n",
       "\n",
       "                        homepage_url  \\\n",
       "0                 http://livfame.com   \n",
       "1             http://www.qounter.com   \n",
       "2                http://oneofthem.jp   \n",
       "3                 http://www.0-6.com   \n",
       "4  http://004gmbh.de/en/004-interact   \n",
       "\n",
       "                                       category_list  funding_total_usd  \\\n",
       "0                                            [Media]         10000000.0   \n",
       "1  [Application Platforms, Real Time, Social Netw...           700000.0   \n",
       "2                              [Apps, Games, Mobile]          3406878.0   \n",
       "3                                      [Curated Web]          2000000.0   \n",
       "4                                         [Software]          3200000.0   \n",
       "\n",
       "  country_code state_code                 region           city  \\\n",
       "0          IND         16                 Mumbai         Mumbai   \n",
       "1          USA         DE             DE - Other  Delaware City   \n",
       "2          JPN       None                   None           None   \n",
       "3          CHN         22                Beijing        Beijing   \n",
       "4          USA         IL  Springfield, Illinois      Champaign   \n",
       "\n",
       "   funding_rounds  ... score_momentum_avg_round score_momentum_per_year  \\\n",
       "0               1  ...                      1.0                     3.0   \n",
       "1               2  ...                      5.0                     7.0   \n",
       "2               1  ...                      3.0                     5.0   \n",
       "3               1  ...                      3.0                     7.0   \n",
       "4               1  ...                      3.0                     5.0   \n",
       "\n",
       "  score_age  score_diversification  score_inflation  score_gdp_growth  \\\n",
       "0         1                      5                5                 1   \n",
       "1         1                      3                3                 1   \n",
       "2         1                      3                1                 3   \n",
       "3         1                      5                1                 3   \n",
       "4         1                      5                3                 1   \n",
       "\n",
       "   score_unemployment_rate  score_total  rating  pd_model  \n",
       "0                        5     6.587360      R5      0.35  \n",
       "1                        3     5.614708      R4      0.20  \n",
       "2                        1     6.732206      R5      0.35  \n",
       "3                        1     7.483330      R5      0.35  \n",
       "4                        3     6.326976      R4      0.20  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deriving quantile bands...\n",
      "Rating cutoffs: [-2.523685711022103, 0.5697205670588253, 1.1586209665291574, 1.6927172613391437]\n",
      "4 5\n"
     ]
    }
   ],
   "source": [
    "policy = src_2.CreditPolicy.from_training(\n",
    "            df=df_comp[df_comp[\"target_binary\"].notna()],\n",
    "            comp_cols=[c for c in df_comp.columns if c.startswith(\n",
    "                (\"funding_total_usd\", \"diff_\", \"years_since_\", \"country_rate\",\n",
    "                \"sector_rate\",\"inflation\", \"gdp_growth\", \"unemployment_rate\")\n",
    "            )],\n",
    "        )\n",
    "#print(policy)\n",
    "policy.to_yaml(\"policy_latest.yaml\")\n",
    "df_scored = policy.apply(df_comp, scenario=\"severe\")\n",
    "df_scored.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pycountry\n",
    "import polars as pl\n",
    "\n",
    "def join_dfs(df) -> tuple:\n",
    "    \"\"\"\n",
    "    Process CSV files in the given folder by:\n",
    "      1. Converting specified year columns: casting to string, replacing \"no data\" with null,\n",
    "         casting to Float64, and filling nulls with the 25th percentile.\n",
    "      2. Renaming the first column to 'country' if needed.\n",
    "      3. Extracting the text before a comma in the 'country' column and mapping it\n",
    "         via countries_mapping to get a new 'country_code' column.\n",
    "      4. Assuming there are three CSVs (unemployment, GDP per capita, inflation) in the folder,\n",
    "         each DataFrame is further processed to melt the data to a long format and impute missing\n",
    "         values using the mean of bordering countries.\n",
    "    \n",
    "    Parameters:\n",
    "\n",
    "      neighbors_json_path (str): Path to a JSON file mapping countries to their neighbors.\n",
    "      \n",
    "    Returns:\n",
    "      Tuple of Polars DataFrames: (unempl_filled, gdp_filled, infl_filled)\n",
    "    \"\"\"\n",
    "    databank = pl.read_excel(r\"ExternalData\\P_Data_Extract_From_World_Development_Indicators.xlsx\")\n",
    "\n",
    "    unempl=databank.filter(pl.col(\"Series Code\")==\"SL.UEM.TOTL.NE.ZS\").drop(\"Series Code\",\"Series Name\", \"Country Code\")\n",
    "    ease_of_business=databank.filter(pl.col(\"Series Code\")==\"IC.BUS.DFRN.XQ\").drop(\"Series Code\",\"Series Name\", \"Country Code\")\n",
    "    cost_business=databank.filter(pl.col(\"Series Code\")==\"IC.REG.COST.PC.ZS\").drop(\"Series Code\",\"Series Name\", \"Country Code\")\n",
    "    r_d=databank.filter(pl.col(\"Series Code\")==\"IC.FRM.RSDV.ZS\").drop(\"Series Code\",\"Series Name\", \"Country Code\")\n",
    "    formal_training=databank.filter(pl.col(\"Series Code\")==\"IC.FRM.TRNG.ZS\").drop(\"Series Code\",\"Series Name\", \"Country Code\")\n",
    "    theft=databank.filter(pl.col(\"Series Code\")==\"IC.FRM.THEV.ZS\").drop(\"Series Code\",\"Series Name\", \"Country Code\")\n",
    "    market_cap=pl.read_csv(r\"ExternalData\\API_CM.MKT.LCAP.CD_DS2_en_csv_v2_18160.csv\",skip_rows=4).drop(\"Indicator Name\",\"Indicator Name\", \"Country Code\")\n",
    "    urban=pl.read_csv(r\"ExternalData\\API_SP.URB.TOTL.IN.ZS_DS2_en_csv_v2_13366.csv\",skip_rows=4).drop(\"Indicator Name\",\"Indicator Name\", \"Country Code\")\n",
    "    lend=pl.read_csv(r\"ExternalData\\API_FR.INR.LEND_DS2_en_csv_v2_15559.csv\",skip_rows=4).drop(\"Indicator Name\",\"Indicator Name\", \"Country Code\")\n",
    "    credit=pl.read_csv(r\"ExternalData\\API_IC.CRD.INFO.XQ_DS2_en_csv_v2_18417.csv\",skip_rows=4).drop(\"Indicator Name\",\"Indicator Name\", \"Country Code\")\n",
    "    legal=pl.read_csv(r\"ExternalData\\API_IC.LGL.CRED.XQ_DS2_en_csv_v2_18437.csv\",skip_rows=4).drop(\"Indicator Name\",\"Indicator Name\", \"Country Code\")\n",
    "    export=pl.read_csv(r\"ExternalData\\API_NE.EXP.GNFS.ZS_DS2_en_csv_v2_13376.csv\",skip_rows=4).drop(\"Indicator Name\",\"Indicator Name\", \"Country Code\")\n",
    "    \n",
    "    gdp = pl.read_excel(r\"ExternalData\\imf-dm-export-20250330_gdp_capita_ppi.xls\")\n",
    "    infl = pl.read_excel(r\"ExternalData\\imf-dm-export-20250330_infl.xls\")\n",
    "    \n",
    "    dfs = [unempl, gdp, infl, ease_of_business, cost_business, r_d, formal_training, theft, market_cap, urban, lend, credit, legal, export]\n",
    "    countries_mapping = {country.name: country.alpha_3 for country in pycountry.countries}\n",
    "    year_cols = [str(year) for year in range(1980, 2024)]\n",
    "    neighbors_json_path=r\"ExternalData\\neighbors_of_countries.json\"\n",
    "    processed_dfs = []\n",
    "    \n",
    "    # Iterate through CSV files (sorted to ensure a consistent order)\n",
    "    for data in dfs:\n",
    "        for col in data.columns:\n",
    "            if col[0:2] in [\"19\",\"20\"]:\n",
    "                    # Convert column to string (Utf8) first\n",
    "                    data = data.with_columns(pl.col(col).cast(pl.Utf8).alias(col))\n",
    "                    \n",
    "                    # Replace \"no data\" with null and cast to float\n",
    "                    data = data.with_columns(\n",
    "                        pl.when(pl.col(col) == \"no data\")\n",
    "                          .then(pl.lit(None))\n",
    "                          .when(pl.col(col) == \"\")\n",
    "                          .then(pl.lit(None))\n",
    "                          .otherwise(pl.col(col))\n",
    "                          .cast(pl.Float64)\n",
    "                          .alias(col)\n",
    "                    ) \n",
    "\n",
    "                    data = data.with_columns(\n",
    "                        pl.col(col)\n",
    "                        .fill_null(pl.col(col).quantile(0.25))\n",
    "                        .alias(col)\n",
    "                    )\n",
    "            \n",
    "            first_col = data.columns[0]\n",
    "            if first_col != \"country\":\n",
    "                data = data.rename({first_col: \"country\"})\n",
    "            \n",
    "            data = data.with_columns(\n",
    "                pl.col(\"country\")\n",
    "                  .str.extract(r\"^([^,]+)\")\n",
    "                  .replace(countries_mapping)\n",
    "                  .alias(\"country_code\")\n",
    "            )\n",
    "        processed_dfs.append(data)\n",
    "    \n",
    "    if len(processed_dfs) < 3:\n",
    "        raise ValueError(\"Expected at least three CSV files for unemployment, GDP, and inflation data.\")\n",
    "    \n",
    "    # ========= STEP 3: Impute Missing External Data Using Bordering Countries =========\n",
    "    with open(neighbors_json_path, \"r\") as f:\n",
    "        borders_mapping = json.load(f)\n",
    "    \n",
    "    def get_alpha3(country_str: str) -> str:\n",
    "        \"\"\"Return the ISO alpha-3 code for a given country name or official name.\"\"\"\n",
    "        country_obj = pycountry.countries.get(name=country_str)\n",
    "        if country_obj is None:\n",
    "            country_obj = pycountry.countries.get(official_name=country_str)\n",
    "        return country_obj.alpha_3 if country_obj is not None else None\n",
    "    \n",
    "    # Build a DataFrame of borders where each row is a mapping from a country to one of its neighbors.\n",
    "    rows = []\n",
    "    for country, neighbors in borders_mapping.items():\n",
    "        main_code = get_alpha3(country)\n",
    "        if main_code is None:\n",
    "            continue\n",
    "        for neighbor in neighbors.keys():\n",
    "            neighbor_code = get_alpha3(neighbor)\n",
    "            if neighbor_code is not None:\n",
    "                rows.append({\"country\": main_code, \"neighbor\": neighbor_code})\n",
    "    borders_df = pl.DataFrame(rows)\n",
    "    \n",
    "    def process_external(data: pl.DataFrame, value_col: str) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the external data (e.g. unemployment, GDP, inflation) to a long format,\n",
    "        then join bordering country information to compute the mean of neighbor values to\n",
    "        fill in missing data.\n",
    "        \"\"\"\n",
    "        # Melt to long format\n",
    "        data_long = data.melt(\n",
    "            id_vars=\"country_code\",\n",
    "            value_vars=year_cols,\n",
    "            variable_name=\"year\",\n",
    "            value_name=value_col\n",
    "        ).with_columns(pl.col(\"year\").cast(pl.Int64))\n",
    "        \n",
    "        # Join with borders_df to gather neighboring information\n",
    "        neighbors_data = data_long.join(\n",
    "            borders_df,\n",
    "            left_on=\"country_code\",\n",
    "            right_on=\"neighbor\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        # For each main country and year, compute the mean of the value from its neighbors\n",
    "        neighbors_mean = neighbors_data.group_by([\"country\", \"year\"]).agg(\n",
    "            pl.col(value_col).mean().alias(f\"{value_col}_mean\")\n",
    "        )\n",
    "        \n",
    "        # Join the computed neighbor means back to the long DataFrame and fill nulls\n",
    "        data_filled = data_long.join(\n",
    "            neighbors_mean,\n",
    "            left_on=[\"country_code\", \"year\"],\n",
    "            right_on=[\"country\", \"year\"],\n",
    "            how=\"left\"\n",
    "        ).with_columns(\n",
    "            pl.col(f\"{value_col}_mean\").cast(pl.Float64),\n",
    "            pl.when(pl.col(value_col).is_null())\n",
    "              .then(pl.col(f\"{value_col}_mean\"))\n",
    "              .otherwise(pl.col(value_col)).cast(pl.Float64)\n",
    "              .alias(value_col),\n",
    "        )\n",
    "        return data_filled\n",
    "\n",
    "    dfs = [unempl, gdp, infl, ease_of_business, cost_business, r_d, formal_training, theft, market_cap, urban, lend, credit, legal, export]\n",
    "\n",
    "    unempl_filled = process_external(processed_dfs[0], \"unemployment_rate\")\n",
    "    gdp_filled   = process_external(processed_dfs[1], \"gdp_per_capita\")\n",
    "    infl_filled  = process_external(processed_dfs[2], \"inflation\")\n",
    "    ease_of_business_filled = process_external(processed_dfs[3], \"ease_of_business\")\n",
    "    cost_business_filled = process_external(processed_dfs[4], \"cost_business\")\n",
    "    r_d_filled = process_external(processed_dfs[5], \"r_d\")\n",
    "    formal_training_filled = process_external(processed_dfs[6], \"formal_training\")\n",
    "    theft_filled = process_external(processed_dfs[7], \"theft\") \n",
    "    market_cap_filled = process_external(processed_dfs[8], \"market_cap\")\n",
    "    urban_filled = process_external(processed_dfs[9], \"urban\")\n",
    "    lend_filled = process_external(processed_dfs[10], \"lend\")\n",
    "    credit_filled = process_external(processed_dfs[11], \"credit\")\n",
    "    legal_filled = process_external(processed_dfs[12], \"legal\")\n",
    "    export_filled = process_external(processed_dfs[13], \"export\")\n",
    "\n",
    "    themes =[\"unemployment_rate\", \"gdp_per_capita\", \"inflation\", \"ease_of_business\", \"cost_business\", \"r_d\", \"formal_training\", \"theft\", \"market_cap\", \"urban\", \"lend\", \"credit\", \"legal\", \"export\"]    \n",
    "    dfs_filled=[unempl_filled, gdp_filled, infl_filled, ease_of_business_filled, cost_business_filled, r_d_filled, formal_training_filled, theft_filled, market_cap_filled, urban_filled, lend_filled, credit_filled, legal_filled, export_filled]\n",
    "\n",
    "    for j,df_filled in enumerate(dfs_filled):\n",
    "        for i in ['foundation_year', 'first_funding_year', 'last_funding_year']:\n",
    "            suffix = f\"_{i.split('_')[0]}\"\n",
    "            \n",
    "            df = df.join(\n",
    "                df_filled,\n",
    "                left_on=[\"country_code\", i],\n",
    "                right_on=[\"country_code\", \"year\"],\n",
    "                how=\"left\",\n",
    "                suffix=suffix\n",
    "            ).with_columns(\n",
    "                pl.col(f\"{themes[j]}{suffix if i!='foundation_year' else ''}\").fill_null(pl.col(f\"{themes[j]}{suffix if i!='foundation_year' else ''}\").quantile(0.25).over([\"subregion\"])).fill_null(pl.col(f\"{themes[j]}{suffix if i!='foundation_year' else ''}\").quantile(0.25)),\n",
    "                pl.col(f\"{themes[j]}_mean{suffix if i!='foundation_year' else ''}\").fill_null(pl.col(f\"{themes[j]}_mean{suffix if i!='foundation_year' else ''}\").quantile(0.25).over([\"subregion\"])).fill_null(pl.col(f\"{themes[j]}_mean{suffix if i!='foundation_year' else ''}\").quantile(0.25)),\n",
    "            )\n",
    "    \n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
